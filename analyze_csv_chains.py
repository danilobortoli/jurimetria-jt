#!/usr/bin/env python3
"""
An√°lise do CSV Consolidado para Identificar Cadeias Processuais
Verifica se mesmos casos est√£o distribu√≠dos em arquivos diferentes.
"""

import csv
import pandas as pd
from pathlib import Path
from typing import Dict, List, Any
from collections import defaultdict, Counter
from datetime import datetime

def analyze_csv_chains(csv_file: str):
    """Analisa cadeias processuais no CSV consolidado."""
    
    print(f"üîç Analisando cadeias processuais em: {csv_file}")
    
    # Carrega dados
    df = pd.read_csv(csv_file)
    print(f"üìä Carregados {len(df):,} registros")
    
    # An√°lise por n√∫mero_core (casos relacionados)
    cores_analysis = df.groupby('numero_core').agg({
        'numero_processo': 'count',
        'grau': lambda x: list(x.unique()),
        'tribunal': lambda x: list(x.unique()),
        'arquivo_origem': lambda x: list(x.unique()),
        'instancia_normalizada': lambda x: list(x.unique()),
        'ano_processo': 'first'
    }).rename(columns={'numero_processo': 'count_instances'})
    
    # Filtra casos com m√∫ltiplas inst√¢ncias
    multi_instance = cores_analysis[cores_analysis['count_instances'] > 1]
    print(f"üîó Casos com m√∫ltiplas inst√¢ncias: {len(multi_instance):,}")
    
    # Analisa distribui√ß√£o de arquivos
    multi_files = multi_instance[multi_instance['arquivo_origem'].apply(len) > 1]
    print(f"üìÅ Casos em m√∫ltiplos arquivos: {len(multi_files):,}")
    
    # Estat√≠sticas detalhadas
    print(f"\nüìà AN√ÅLISE DETALHADA:")
    print(f"=" * 50)
    
    # Distribui√ß√£o por n√∫mero de inst√¢ncias
    instance_counts = Counter(multi_instance['count_instances'])
    print(f"\nüî¢ Distribui√ß√£o por n√∫mero de inst√¢ncias:")
    for count, cases in sorted(instance_counts.items()):
        print(f"  {count} inst√¢ncias: {cases:,} casos")
    
    # Casos com fluxo completo G1‚ÜíG2‚ÜíTST
    complete_flows = multi_instance[
        multi_instance['instancia_normalizada'].apply(
            lambda x: all(inst in x for inst in ['Primeira Inst√¢ncia', 'Segunda Inst√¢ncia', 'TST'])
        )
    ]
    print(f"\n‚öñÔ∏è Fluxos completos (G1‚ÜíG2‚ÜíTST): {len(complete_flows):,}")
    
    # Casos apenas G1‚ÜíTST (sem G2)
    g1_tst_only = multi_instance[
        multi_instance['instancia_normalizada'].apply(
            lambda x: 'Primeira Inst√¢ncia' in x and 'TST' in x and 'Segunda Inst√¢ncia' not in x
        )
    ]
    print(f"üîÄ Fluxos G1‚ÜíTST (sem G2): {len(g1_tst_only):,}")
    
    # An√°lise de arquivos cruzados
    print(f"\nüìÇ AN√ÅLISE DE DISTRIBUI√á√ÉO POR ARQUIVOS:")
    print(f"=" * 50)
    
    # Casos que est√£o em arquivos de tribunais diferentes
    cross_tribunal_cases = multi_files[
        multi_files['arquivo_origem'].apply(
            lambda files: len(set(f.split('_')[0] for f in files if '_' in f)) > 1
        )
    ]
    print(f"üèõÔ∏è Casos em arquivos de tribunais diferentes: {len(cross_tribunal_cases):,}")
    
    # Exemplos de casos distribu√≠dos
    print(f"\nüîç EXEMPLOS DE CASOS DISTRIBU√çDOS:")
    print(f"=" * 50)
    
    for i, (core, data) in enumerate(multi_files.head(10).iterrows()):
        print(f"\nCaso {i+1}: Core {core}")
        print(f"  Inst√¢ncias: {data['count_instances']}")
        print(f"  Graus: {', '.join(data['grau'])}")
        print(f"  Tribunais: {', '.join(data['tribunal'])}")
        print(f"  Arquivos: {', '.join(data['arquivo_origem'])}")
    
    # An√°lise de resultados por inst√¢ncia
    print(f"\n‚öñÔ∏è AN√ÅLISE DE RESULTADOS:")
    print(f"=" * 50)
    
    # Filtra apenas casos de ass√©dio moral
    df_assedio = df[df['eh_assedio_moral'] == True]
    
    # Estat√≠sticas por inst√¢ncia
    by_instance = df_assedio.groupby('instancia_normalizada').agg({
        'tem_resultado_primeira': lambda x: sum(x == True),
        'tem_resultado_recurso': lambda x: sum(x == True),
        'numero_processo': 'count'
    }).rename(columns={'numero_processo': 'total_cases'})
    
    print("Por inst√¢ncia (apenas ass√©dio moral):")
    for instance, data in by_instance.iterrows():
        print(f"  {instance}:")
        print(f"    Total: {data['total_cases']:,}")
        print(f"    Com resultado 1¬™ inst: {data['tem_resultado_primeira']:,}")
        print(f"    Com resultado recurso: {data['tem_resultado_recurso']:,}")
    
    # Salva resultados detalhados
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Salva casos multi-inst√¢ncia
    multi_instance_file = f"casos_multiinstancia_{timestamp}.csv"
    multi_instance.to_csv(multi_instance_file)
    print(f"\nüíæ Casos multi-inst√¢ncia salvos em: {multi_instance_file}")
    
    # Salva casos em m√∫ltiplos arquivos  
    multi_files_file = f"casos_multiplos_arquivos_{timestamp}.csv"
    multi_files.to_csv(multi_files_file)
    print(f"üíæ Casos em m√∫ltiplos arquivos salvos em: {multi_files_file}")
    
    # An√°lise espec√≠fica de cadeias completas
    analyze_complete_chains(df_assedio, complete_flows)
    
    return {
        'total_cases': len(df),
        'multi_instance_cases': len(multi_instance),
        'multi_file_cases': len(multi_files),
        'complete_flows': len(complete_flows),
        'g1_tst_only': len(g1_tst_only),
        'cross_tribunal_cases': len(cross_tribunal_cases)
    }

def analyze_complete_chains(df_assedio, complete_flows):
    """Analisa cadeias completas G1‚ÜíG2‚ÜíTST."""
    
    print(f"\nüéØ AN√ÅLISE DE CADEIAS COMPLETAS G1‚ÜíG2‚ÜíTST:")
    print(f"=" * 50)
    
    # Para cada cadeia completa, analisa o fluxo
    chain_results = []
    
    for core in complete_flows.index[:20]:  # Primeiros 20 para an√°lise
        chain_data = df_assedio[df_assedio['numero_core'] == core].sort_values('grau')
        
        if len(chain_data) >= 3:  # G1, G2, TST
            g1_data = chain_data[chain_data['instancia_normalizada'] == 'Primeira Inst√¢ncia'].iloc[0]
            g2_data = chain_data[chain_data['instancia_normalizada'] == 'Segunda Inst√¢ncia'].iloc[0]
            tst_data = chain_data[chain_data['instancia_normalizada'] == 'TST'].iloc[0]
            
            # Extrai resultados
            resultado_g1 = g1_data['resultado_primeira_nome'] if g1_data['tem_resultado_primeira'] else 'Sem resultado'
            resultado_g2 = g2_data['resultado_recurso_nome'] if g2_data['tem_resultado_recurso'] else 'Sem resultado'
            resultado_tst = tst_data['resultado_recurso_nome'] if tst_data['tem_resultado_recurso'] else 'Sem resultado'
            
            # Determina resultado final (se poss√≠vel)
            worker_won = None
            if resultado_g1 != 'Sem resultado' and resultado_tst != 'Sem resultado':
                trabalhador_ganhou_g1 = resultado_g1 in ['Proced√™ncia', 'Proced√™ncia em Parte']
                tst_provido = resultado_tst in ['Provimento', 'Provimento em Parte']
                
                if trabalhador_ganhou_g1:
                    worker_won = not tst_provido  # Se TST proveu, trabalhador perdeu
                else:
                    worker_won = tst_provido  # Se TST proveu, trabalhador ganhou
            
            chain_info = {
                'core': core,
                'g1_tribunal': g1_data['tribunal'],
                'g2_tribunal': g2_data['tribunal'], 
                'tst_tribunal': tst_data['tribunal'],
                'resultado_g1': resultado_g1,
                'resultado_g2': resultado_g2,
                'resultado_tst': resultado_tst,
                'worker_won': worker_won,
                'arquivos': f"{g1_data['arquivo_origem']} | {g2_data['arquivo_origem']} | {tst_data['arquivo_origem']}"
            }
            
            chain_results.append(chain_info)
    
    # Imprime exemplos
    print(f"Analisando {len(chain_results)} cadeias completas:")
    
    determinable_results = [c for c in chain_results if c['worker_won'] is not None]
    if determinable_results:
        worker_wins = sum(1 for c in determinable_results if c['worker_won'])
        success_rate = (worker_wins / len(determinable_results)) * 100
        
        print(f"\nüìä Resultados determin√°veis: {len(determinable_results)}")
        print(f"‚öñÔ∏è Taxa de sucesso do trabalhador: {success_rate:.1f}%")
        print(f"‚úÖ Vit√≥rias: {worker_wins}")
        print(f"‚ùå Derrotas: {len(determinable_results) - worker_wins}")
    
    # Mostra exemplos
    print(f"\nüîç EXEMPLOS DE CADEIAS COMPLETAS:")
    for i, chain in enumerate(chain_results[:5]):
        print(f"\nCadeia {i+1} (Core: {chain['core']}):")
        print(f"  G1 ({chain['g1_tribunal']}): {chain['resultado_g1']}")
        print(f"  G2 ({chain['g2_tribunal']}): {chain['resultado_g2']}")
        print(f"  TST: {chain['resultado_tst']}")
        if chain['worker_won'] is not None:
            resultado = "Trabalhador GANHOU" if chain['worker_won'] else "Trabalhador PERDEU"
            print(f"  Resultado final: {resultado}")
        print(f"  Arquivos: {chain['arquivos']}")

def main():
    """Fun√ß√£o principal."""
    import argparse
    
    parser = argparse.ArgumentParser(description="An√°lise de Cadeias no CSV")
    parser.add_argument("--csv-file", type=str,
                       default="consolidated_all_data.csv",
                       help="Arquivo CSV para an√°lise")
    
    args = parser.parse_args()
    
    if not Path(args.csv_file).exists():
        print(f"‚ùå Arquivo n√£o encontrado: {args.csv_file}")
        return
    
    analyze_csv_chains(args.csv_file)

if __name__ == "__main__":
    main()